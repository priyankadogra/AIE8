{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Social Media ML Paper Agent - Multi-Agent LangGraph System\n",
        "\n",
        "This notebook implements a multi-agent system that creates social media posts about Machine Learning papers and verifies their correctness and platform appropriateness.\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "The system consists of three main teams:\n",
        "\n",
        "1. **Content Creation Team**: Analyzes ML papers and creates social media content\n",
        "   - Paper Analyzer Agent\n",
        "   - Content Creator Agent\n",
        "   - Platform Optimizer Agent\n",
        "\n",
        "2. **Verification Team**: Verifies correctness and platform appropriateness\n",
        "   - Technical Reviewer Agent\n",
        "   - Style Checker Agent\n",
        "   - Fact Checker Agent\n",
        "\n",
        "3. **Meta-Supervisor**: Coordinates between teams and manages the overall workflow\n",
        "\n",
        "![System Architecture](https://i.imgur.com/placeholder.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, List, Optional, TypedDict, Union, Dict, Annotated\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool, tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    \"\"\"Helper function to create agent nodes\"\"\"\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
        "\n",
        "def create_agent(\n",
        "    llm: ChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> str:\n",
        "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason!\")\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor\n",
        "\n",
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
        "    \"\"\"An LLM-based router.\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [\n",
        "                        {\"enum\": options},\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Given the conversation above, who should act next?\"\n",
        "                \" Or should we FINISH? Select one of: {options}\",\n",
        "            ),\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=\", \".join(members))\n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create working directory for storing content\n",
        "os.makedirs('./social_media_content', exist_ok=True)\n",
        "\n",
        "def create_random_subdirectory():\n",
        "    random_id = str(uuid.uuid4())[:8]\n",
        "    subdirectory_path = os.path.join('./social_media_content', random_id)\n",
        "    os.makedirs(subdirectory_path, exist_ok=True)\n",
        "    return subdirectory_path\n",
        "\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "# Initialize search tool\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_ml_paper_info(\n",
        "    query: Annotated[str, \"Search query for ML paper information\"]\n",
        ") -> str:\n",
        "    \"\"\"Search for information about machine learning papers, authors, or concepts.\"\"\"\n",
        "    return tavily_tool.invoke(query)\n",
        "\n",
        "@tool\n",
        "def create_social_media_post(\n",
        "    platform: Annotated[str, \"Social media platform (twitter, linkedin, instagram)\"],\n",
        "    content: Annotated[str, \"Main content of the post\"],\n",
        "    hashtags: Annotated[List[str], \"List of relevant hashtags\"],\n",
        "    file_name: Annotated[str, \"File name to save the post\"]\n",
        ") -> str:\n",
        "    \"\"\"Create a social media post optimized for a specific platform.\"\"\"\n",
        "    \n",
        "    platform_configs = {\n",
        "        \"twitter\": {\"char_limit\": 280, \"hashtag_limit\": 5},\n",
        "        \"linkedin\": {\"char_limit\": 3000, \"hashtag_limit\": 10},\n",
        "        \"instagram\": {\"char_limit\": 2200, \"hashtag_limit\": 30}\n",
        "    }\n",
        "    \n",
        "    config = platform_configs.get(platform.lower(), platform_configs[\"twitter\"])\n",
        "    \n",
        "    # Format hashtags\n",
        "    formatted_hashtags = [f\"#{tag.replace('#', '')}\" for tag in hashtags[:config[\"hashtag_limit\"]]]\n",
        "    hashtag_string = \" \".join(formatted_hashtags)\n",
        "    \n",
        "    # Create platform-specific post\n",
        "    if platform.lower() == \"twitter\":\n",
        "        post = f\"{content}\\n\\n{hashtag_string}\"\n",
        "    elif platform.lower() == \"linkedin\":\n",
        "        post = f\"{content}\\n\\n{hashtag_string}\\n\\n#MachineLearning #AI #Research\"\n",
        "    else:  # Instagram\n",
        "        post = f\"{content}\\n\\n{hashtag_string}\"\n",
        "    \n",
        "    # Truncate if necessary\n",
        "    if len(post) > config[\"char_limit\"]:\n",
        "        post = post[:config[\"char_limit\"]-3] + \"...\"\n",
        "    \n",
        "    # Save to file\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(f\"Platform: {platform}\\n\")\n",
        "        file.write(f\"Character count: {len(post)}\\n\")\n",
        "        file.write(f\"Hashtag count: {len(formatted_hashtags)}\\n\")\n",
        "        file.write(\"\\n--- POST CONTENT ---\\n\")\n",
        "        file.write(post)\n",
        "    \n",
        "    return f\"Social media post created and saved to {file_name}. Character count: {len(post)}\"\n",
        "\n",
        "@tool\n",
        "def read_content_file(\n",
        "    file_name: Annotated[str, \"Name of the file to read\"]\n",
        ") -> str:\n",
        "    \"\"\"Read the content of a saved file.\"\"\"\n",
        "    try:\n",
        "        with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"File {file_name} not found.\"\n",
        "\n",
        "@tool\n",
        "def verify_technical_accuracy(\n",
        "    paper_info: Annotated[str, \"Information about the ML paper\"],\n",
        "    social_post: Annotated[str, \"Social media post content\"]\n",
        ") -> str:\n",
        "    \"\"\"Verify that the social media post accurately represents the technical content of the paper.\"\"\"\n",
        "    \n",
        "    verification_report = f\"\"\"\n",
        "    TECHNICAL ACCURACY VERIFICATION REPORT\n",
        "    \n",
        "    Paper Information:\n",
        "    {paper_info}\n",
        "    \n",
        "    Social Media Post:\n",
        "    {social_post}\n",
        "    \n",
        "    Verification Checklist:\n",
        "    □ Technical claims are accurate\n",
        "    □ No oversimplification that leads to misinformation\n",
        "    □ Proper attribution to authors\n",
        "    □ Results and claims are not exaggerated\n",
        "    □ Methodology is correctly described\n",
        "    \n",
        "    Recommendations:\n",
        "    - Check for any technical inaccuracies\n",
        "    - Ensure claims are supported by the paper\n",
        "    - Verify that complex concepts are simplified appropriately\n",
        "    \"\"\"\n",
        "    \n",
        "    return verification_report\n",
        "\n",
        "@tool\n",
        "def check_platform_style(\n",
        "    platform: Annotated[str, \"Social media platform\"],\n",
        "    post_content: Annotated[str, \"Social media post content\"]\n",
        ") -> str:\n",
        "    \"\"\"Check if the post follows the style and best practices for the target platform.\"\"\"\n",
        "    \n",
        "    platform_guidelines = {\n",
        "        \"twitter\": {\n",
        "            \"tone\": \"Concise, engaging, conversational\",\n",
        "            \"best_practices\": [\"Use threads for complex topics\", \"Include relevant hashtags\", \"Tag authors if possible\"],\n",
        "            \"char_limit\": 280\n",
        "        },\n",
        "        \"linkedin\": {\n",
        "            \"tone\": \"Professional, informative, thought-provoking\",\n",
        "            \"best_practices\": [\"Start with a hook\", \"Use line breaks for readability\", \"End with a question or call-to-action\"],\n",
        "            \"char_limit\": 3000\n",
        "        },\n",
        "        \"instagram\": {\n",
        "            \"tone\": \"Visual, engaging, accessible\",\n",
        "            \"best_practices\": [\"Use emojis appropriately\", \"Include many relevant hashtags\", \"Make it visually appealing\"],\n",
        "            \"char_limit\": 2200\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    guidelines = platform_guidelines.get(platform.lower(), platform_guidelines[\"twitter\"])\n",
        "    \n",
        "    style_report = f\"\"\"\n",
        "    PLATFORM STYLE VERIFICATION REPORT\n",
        "    \n",
        "    Platform: {platform}\n",
        "    Expected Tone: {guidelines['tone']}\n",
        "    Character Limit: {guidelines['char_limit']}\n",
        "    \n",
        "    Post Content:\n",
        "    {post_content}\n",
        "    \n",
        "    Style Checklist:\n",
        "    □ Appropriate tone for platform\n",
        "    □ Within character limits\n",
        "    □ Follows platform best practices\n",
        "    □ Engaging and accessible language\n",
        "    □ Proper use of hashtags and mentions\n",
        "    \n",
        "    Best Practices for {platform}:\n",
        "    {chr(10).join(['- ' + practice for practice in guidelines['best_practices']])}\n",
        "    \n",
        "    Recommendations:\n",
        "    - Ensure the tone matches the platform audience\n",
        "    - Check character count and hashtag usage\n",
        "    - Verify engagement potential\n",
        "    \"\"\"\n",
        "    \n",
        "    return style_report\n",
        "\n",
        "@tool\n",
        "def save_verification_report(\n",
        "    report_content: Annotated[str, \"Verification report content\"],\n",
        "    file_name: Annotated[str, \"File name for the report\"]\n",
        ") -> str:\n",
        "    \"\"\"Save a verification report to a file.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(report_content)\n",
        "    return f\"Verification report saved to {file_name}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Team States and Complete System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Team State Definitions\n",
        "class ContentTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str\n",
        "\n",
        "class VerificationTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str\n",
        "\n",
        "class MetaState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    next: str\n",
        "\n",
        "# Helper function to track files\n",
        "def content_prelude(state):\n",
        "    written_files = []\n",
        "    if WORKING_DIRECTORY.exists():\n",
        "        try:\n",
        "            written_files = [f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\") if f.is_file()]\n",
        "        except:\n",
        "            pass\n",
        "    return state\n",
        "\n",
        "# Initialize LLMs with different models for different purposes\n",
        "content_llm = ChatOpenAI(model=\"gpt-4o-mini\")  # Fast and cost-effective for content creation\n",
        "verification_llm = ChatOpenAI(model=\"gpt-4o\")  # More powerful model for critical verification tasks\n",
        "meta_llm = ChatOpenAI(model=\"gpt-4o-mini\")    # Efficient for coordination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Content Creation Team Agents\n",
        "paper_analyzer_agent = create_agent(\n",
        "    content_llm,\n",
        "    [search_ml_paper_info],\n",
        "    \"You are an expert ML researcher who analyzes papers to extract key insights for social media content.\"\n",
        ")\n",
        "paper_analyzer_node = functools.partial(agent_node, agent=paper_analyzer_agent, name=\"PaperAnalyzer\")\n",
        "\n",
        "content_creator_agent = create_agent(\n",
        "    content_llm,\n",
        "    [create_social_media_post, read_content_file],\n",
        "    \"You are a social media content creator who makes complex ML research accessible and engaging.\"\n",
        ")\n",
        "content_creator_node = functools.partial(agent_node, agent=content_creator_agent, name=\"ContentCreator\")\n",
        "\n",
        "platform_optimizer_agent = create_agent(\n",
        "    content_llm,\n",
        "    [create_social_media_post, read_content_file, check_platform_style],\n",
        "    \"You optimize content for specific social media platforms considering character limits and best practices.\"\n",
        ")\n",
        "platform_optimizer_node = functools.partial(agent_node, agent=platform_optimizer_agent, name=\"PlatformOptimizer\")\n",
        "\n",
        "# Content Team Supervisor\n",
        "content_supervisor_agent = create_team_supervisor(\n",
        "    content_llm,\n",
        "    \"You manage a content creation team. Coordinate: analyze paper → create content → optimize for platform. When ready, respond with FINISH.\",\n",
        "    [\"PaperAnalyzer\", \"ContentCreator\", \"PlatformOptimizer\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Verification Team Agents\n",
        "technical_reviewer_agent = create_agent(\n",
        "    verification_llm,\n",
        "    [read_content_file, verify_technical_accuracy, search_ml_paper_info, save_verification_report],\n",
        "    \"You verify technical accuracy of ML content, ensuring no misinformation or oversimplification.\"\n",
        ")\n",
        "technical_reviewer_node = functools.partial(agent_node, agent=technical_reviewer_agent, name=\"TechnicalReviewer\")\n",
        "\n",
        "style_checker_agent = create_agent(\n",
        "    verification_llm,\n",
        "    [read_content_file, check_platform_style, save_verification_report],\n",
        "    \"You ensure content fits platform requirements including tone, character limits, and engagement strategies.\"\n",
        ")\n",
        "style_checker_node = functools.partial(agent_node, agent=style_checker_agent, name=\"StyleChecker\")\n",
        "\n",
        "fact_checker_agent = create_agent(\n",
        "    verification_llm,\n",
        "    [read_content_file, search_ml_paper_info, save_verification_report],\n",
        "    \"You fact-check claims in social media content and cross-reference with reliable sources.\"\n",
        ")\n",
        "fact_checker_node = functools.partial(agent_node, agent=fact_checker_agent, name=\"FactChecker\")\n",
        "\n",
        "# Verification Team Supervisor\n",
        "verification_supervisor_agent = create_team_supervisor(\n",
        "    verification_llm,\n",
        "    \"You manage a verification team. Ensure comprehensive verification: technical accuracy → platform style → fact-checking. When complete, respond with FINISH.\",\n",
        "    [\"TechnicalReviewer\", \"StyleChecker\", \"FactChecker\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Content Creation Graph\n",
        "content_graph = StateGraph(ContentTeamState)\n",
        "content_graph.add_node(\"PaperAnalyzer\", paper_analyzer_node)\n",
        "content_graph.add_node(\"ContentCreator\", content_creator_node)\n",
        "content_graph.add_node(\"PlatformOptimizer\", platform_optimizer_node)\n",
        "content_graph.add_node(\"ContentSupervisor\", content_supervisor_agent)\n",
        "\n",
        "content_graph.add_edge(\"PaperAnalyzer\", \"ContentSupervisor\")\n",
        "content_graph.add_edge(\"ContentCreator\", \"ContentSupervisor\")\n",
        "content_graph.add_edge(\"PlatformOptimizer\", \"ContentSupervisor\")\n",
        "\n",
        "content_graph.add_conditional_edges(\n",
        "    \"ContentSupervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"PaperAnalyzer\": \"PaperAnalyzer\",\n",
        "        \"ContentCreator\": \"ContentCreator\",\n",
        "        \"PlatformOptimizer\": \"PlatformOptimizer\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "content_graph.set_entry_point(\"ContentSupervisor\")\n",
        "compiled_content_graph = content_graph.compile()\n",
        "compiled_content_graph\n",
        "\n",
        "# Build Verification Graph\n",
        "verification_graph = StateGraph(VerificationTeamState)\n",
        "verification_graph.add_node(\"TechnicalReviewer\", technical_reviewer_node)\n",
        "verification_graph.add_node(\"StyleChecker\", style_checker_node)\n",
        "verification_graph.add_node(\"FactChecker\", fact_checker_node)\n",
        "verification_graph.add_node(\"VerificationSupervisor\", verification_supervisor_agent)\n",
        "\n",
        "verification_graph.add_edge(\"TechnicalReviewer\", \"VerificationSupervisor\")\n",
        "verification_graph.add_edge(\"StyleChecker\", \"VerificationSupervisor\")\n",
        "verification_graph.add_edge(\"FactChecker\", \"VerificationSupervisor\")\n",
        "\n",
        "verification_graph.add_conditional_edges(\n",
        "    \"VerificationSupervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"TechnicalReviewer\": \"TechnicalReviewer\",\n",
        "        \"StyleChecker\": \"StyleChecker\",\n",
        "        \"FactChecker\": \"FactChecker\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "verification_graph.set_entry_point(\"VerificationSupervisor\")\n",
        "compiled_verification_graph = verification_graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ System successfully compiled!\n",
            "📊 Graphs created:\n",
            "   - Content Creation Team\n",
            "   - Verification Team\n",
            "   - Meta-Supervisor\n"
          ]
        }
      ],
      "source": [
        "# Helper functions for meta-supervisor\n",
        "def enter_content_chain(message: str, members: List[str]):\n",
        "    return {\"messages\": [HumanMessage(content=message)], \"team_members\": members}\n",
        "\n",
        "def enter_verification_chain(message: str, members: List[str]):\n",
        "    return {\"messages\": [HumanMessage(content=message)], \"team_members\": members}\n",
        "\n",
        "# Create chain interfaces\n",
        "content_chain = (\n",
        "    functools.partial(enter_content_chain, members=list(content_graph.nodes))\n",
        "    | compiled_content_graph\n",
        ")\n",
        "\n",
        "verification_chain = (\n",
        "    functools.partial(enter_verification_chain, members=list(verification_graph.nodes))\n",
        "    | compiled_verification_graph\n",
        ")\n",
        "\n",
        "# Helper functions for meta state management\n",
        "def get_last_message(state: MetaState) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}\n",
        "\n",
        "# Meta-supervisor\n",
        "meta_supervisor_agent = create_team_supervisor(\n",
        "    meta_llm,\n",
        "    \"You coordinate between content creation and verification teams. First create content, then verify it. When both are complete, respond with FINISH.\",\n",
        "    [\"ContentTeam\", \"VerificationTeam\"],\n",
        ")\n",
        "\n",
        "# Build Meta-Supervisor Graph\n",
        "meta_graph = StateGraph(MetaState)\n",
        "meta_graph.add_node(\"ContentTeam\", get_last_message | content_chain | join_graph)\n",
        "meta_graph.add_node(\"VerificationTeam\", get_last_message | verification_chain | join_graph)\n",
        "meta_graph.add_node(\"MetaSupervisor\", meta_supervisor_agent)\n",
        "\n",
        "meta_graph.add_edge(\"ContentTeam\", \"MetaSupervisor\")\n",
        "meta_graph.add_edge(\"VerificationTeam\", \"MetaSupervisor\")\n",
        "meta_graph.add_conditional_edges(\n",
        "    \"MetaSupervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"ContentTeam\": \"ContentTeam\",\n",
        "        \"VerificationTeam\": \"VerificationTeam\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "meta_graph.set_entry_point(\"MetaSupervisor\")\n",
        "compiled_meta_graph = meta_graph.compile()\n",
        "\n",
        "print(\"✅ System successfully compiled!\")\n",
        "print(\"📊 Graphs created:\")\n",
        "print(\"   - Content Creation Team\")\n",
        "print(\"   - Verification Team\") \n",
        "print(\"   - Meta-Supervisor\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph Structure Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting social media post creation and verification process...\n",
            "📁 Working directory: social_media_content/f9e9491b\n",
            "============================================================\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='The Twitter post about the paper \"Attention Is All You Need\" has been created and optimized! Here’s the final version:\\n\\n---\\n\\n🚀 Dive into the revolution of NLP! 🌟 The paper \"Attention Is All You Need\" by Vaswani et al. introduced the groundbreaking Transformer architecture and self-attention mechanism. 🧠 No more RNNs/CNNs!\\n\\n💡 Key highlights:\\n- Parallel processing = speed 💨\\n- Birthplace of BERT, GPT, and modern LLMs!\\n- State-of-the-art translation results achieved!\\n\\n#NLP #MachineLearning #Transformers #AI #Innovation\\n\\n---\\n\\nThis has been saved in the file **transformer_paper_tweet.txt**.', additional_kwargs={}, response_metadata={}, name='PlatformOptimizer')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'VerificationTeam'}}\n",
            "---\n",
            "{'VerificationTeam': {'messages': [HumanMessage(content='The technical accuracy of the Twitter post about \"Attention Is All You Need\" has been verified. The post accurately describes the key contributions of the paper, such as the introduction of the Transformer architecture and the self-attention mechanism. It correctly mentions the advantages of the model, including parallel processing and its foundational role in developing models like BERT and GPT. The report confirms that all technical claims in the post are accurate and well-represented.', additional_kwargs={}, response_metadata={}, name='FactChecker')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Create a new working directory for this example\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "# Example: Create a Twitter post about the famous Transformer paper\n",
        "example_request = \"\"\"\n",
        "Create a Twitter post about the paper \"Attention Is All You Need\" by Vaswani et al. \n",
        "This is the foundational Transformer paper that introduced the self-attention mechanism \n",
        "and revolutionized natural language processing.\n",
        "\n",
        "Key points:\n",
        "- Introduced the Transformer architecture\n",
        "- Self-attention mechanism eliminates need for RNNs/CNNs\n",
        "- Parallel processing advantages\n",
        "- Foundation for BERT, GPT, and modern LLMs\n",
        "- Achieved state-of-the-art translation results\n",
        "\n",
        "Target platform: Twitter\n",
        "Make it engaging and accessible to a broad audience!\n",
        "\"\"\"\n",
        "\n",
        "print(\"🚀 Starting social media post creation and verification process...\")\n",
        "print(f\"📁 Working directory: {WORKING_DIRECTORY}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for step in compiled_meta_graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=example_request)]},\n",
        "    {\"recursion_limit\": 50}\n",
        "):\n",
        "    if \"__end__\" not in step:\n",
        "        print(step)\n",
        "        print(\"---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Usage - Create a Twitter Post about Transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting social media post creation and verification process...\n",
            "📁 Working directory: social_media_content/1b9a5987\n",
            "============================================================\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='The LinkedIn post about the paper \"Attention Is All You Need\" has been successfully created and saved. It effectively highlights the key points of the Transformer architecture in an engaging manner. If you\\'d like to review or share it, just let me know!', additional_kwargs={}, response_metadata={}, name='PlatformOptimizer')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'VerificationTeam'}}\n",
            "---\n",
            "{'VerificationTeam': {'messages': [HumanMessage(content='It seems that the file containing the LinkedIn post for the paper \"Attention Is All You Need\" is not available. You might want to check if it\\'s saved under a different name or re-save the content correctly. If you can provide the content of the post, I can proceed to verify its technical accuracy.', additional_kwargs={}, response_metadata={}, name='TechnicalReviewer')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'VerificationTeam'}}\n",
            "---\n",
            "{'VerificationTeam': {'messages': [HumanMessage(content='It seems that the file containing the LinkedIn post for the paper \"Attention Is All You Need\" is not available. You might want to check if it\\'s saved under a different name or re-save the content correctly. If you can provide the content of the post, I can proceed to verify its technical accuracy.', additional_kwargs={}, response_metadata={})]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='It seems that the file containing the LinkedIn post for the paper \"Attention Is All You Need\" is not available. You might want to check if it\\'s saved under a different name or re-save the content correctly. If you can provide the content of the post, I can proceed to verify its technical accuracy.', additional_kwargs={}, response_metadata={})]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='It seems that the file containing the LinkedIn post for the paper \"Attention Is All You Need\" is not available. You might want to check if it\\'s saved under a different name or re-save the content correctly. If you can provide the content of the post, I can proceed to verify its technical accuracy.', additional_kwargs={}, response_metadata={})]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='The LinkedIn post content for the paper \"Attention Is All You Need\" is well-structured, informative, and within the character limit for the platform. However, it could benefit from a slight adjustment for better engagement by incorporating a call-to-action at the end. \\n\\n### Suggested Modification:\\n- Add a question at the end to prompt discussions or encourage sharing insights about the paper:\\n\\n**Original Ending:**\\n\"Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762)\"\\n\\n**Revised Ending:**\\n\"Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) What\\'s your take on the impact of Transformers in the AI field?\"\\n\\nWould you like me to make these changes and finalize the post?', additional_kwargs={}, response_metadata={}, name='PlatformOptimizer')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'ContentTeam'}}\n",
            "---\n",
            "{'ContentTeam': {'messages': [HumanMessage(content='The LinkedIn post for \"Attention Is All You Need\" has been successfully updated with a call-to-action at the end. Here’s the finalized content:\\n\\n---\\n\\nThe paper \\'Attention Is All You Need\\' revolutionizes how we approach natural language processing. Introducing the Transformer architecture, it eschews recurrence for self-attention mechanisms, enabling more efficient training and improved performance on various tasks. This innovative model has since become foundational in building state-of-the-art systems across NLP. Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) What\\'s your take on the impact of Transformers in the AI field?\\n\\n#MachineLearning #AI #Transformers #DeepLearning #NLP\\n\\n---\\n\\nThe post has been saved as \"attention_is_all_you_need_linkedin_post.txt\". If you need anything else, just let me know!', additional_kwargs={}, response_metadata={}, name='ContentCreator')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'VerificationTeam'}}\n",
            "---\n",
            "{'VerificationTeam': {'messages': [HumanMessage(content='The LinkedIn post about the paper \"Attention Is All You Need\" is factually accurate. The paper \"Attention Is All You Need,\" authored by Vaswani et al. and first introduced at the NIPS 2017 conference, presents the Transformer model, which uses self-attention mechanisms replacing recurrence found in previous sequence transduction models. This shift has indeed led to improved performance and efficiency in training, becoming foundational in the field of NLP. It is widely recognized as a major advancement in AI and machine learning.\\n\\nThe post correctly reflects these aspects and provides a direct link to the paper for readers who wish to explore further. Therefore, I can confirm the accuracy of the claims in the LinkedIn post. If you need a formal verification report, please let me know!', additional_kwargs={}, response_metadata={}, name='FactChecker')]}}\n",
            "---\n",
            "{'MetaSupervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Create a new working directory for this example\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "# Example: Create a Linkedin post about the famous Transformer paper\n",
        "example_request = \"\"\"\n",
        "Create a LinkedIn post about the paper \"Attention Is All You Need\" by Vaswani et al. \n",
        "This is the foundational Transformer paper that introduced the self-attention mechanism \n",
        "and revolutionized natural language processing.\n",
        "\n",
        "Key points:\n",
        "- Introduced the Transformer architecture\n",
        "- Self-attention mechanism eliminates need for RNNs/CNNs\n",
        "- Parallel processing advantages\n",
        "- Foundation for BERT, GPT, and modern LLMs\n",
        "- Achieved state-of-the-art translation results\n",
        "\n",
        "Target platform: LinkedIn\n",
        "Make it engaging and accessible to a broad audience!\n",
        "\"\"\"\n",
        "\n",
        "print(\"🚀 Starting social media post creation and verification process...\")\n",
        "print(f\"📁 Working directory: {WORKING_DIRECTORY}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for step in compiled_meta_graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=example_request)]},\n",
        "    {\"recursion_limit\": 50}\n",
        "):\n",
        "    if \"__end__\" not in step:\n",
        "        print(step)\n",
        "        print(\"---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 LANGGRAPH VISUAL DIAGRAMS\n",
            "==================================================\n",
            "\n",
            "🔧 Content Creation Team Graph:\n",
            "\n",
            "🔍 Verification Team Graph:\n",
            "\n",
            "🎯 Meta-Supervisor Graph:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x11d42bdf0>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the actual graph objects (same as original notebook)\n",
        "print(\"📊 LANGGRAPH VISUAL DIAGRAMS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\n🔧 Content Creation Team Graph:\")\n",
        "compiled_content_graph\n",
        "\n",
        "print(\"\\n🔍 Verification Team Graph:\")\n",
        "compiled_verification_graph\n",
        "\n",
        "print(\"\\n🎯 Meta-Supervisor Graph:\")\n",
        "compiled_meta_graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Generated Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Files created during the process:\n",
            "========================================\n",
            "\n",
            "📝 attention_is_all_you_need_linkedin_post.txt:\n",
            "------------------------------\n",
            "Platform: linkedin\n",
            "Character count: 652\n",
            "Hashtag count: 5\n",
            "\n",
            "--- POST CONTENT ---\n",
            "The paper 'Attention Is All You Need' revolutionizes how we approach natural language processing. Introducing the Transformer architecture, it eschews recurrence for self-attention mechanisms, enabling more efficient training and improved performance on various tasks. This innovative model has since become foundational in building state-of-the-art systems across NLP. Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) What's your take on the impact of Transformers in the AI field?\n",
            "\n",
            "#MachineLearning #AI #Transformers #DeepLearning #NLP\n",
            "\n",
            "#MachineLearning #AI #Research\n",
            "\n",
            "📝 linkedin_attention_style_verification_report.txt:\n",
            "------------------------------\n",
            "PLATFORM STYLE VERIFICATION REPORT\n",
            "\n",
            "Platform: LinkedIn\n",
            "Expected Tone: Professional, informative, thought-provoking\n",
            "Character Limit: 3000\n",
            "\n",
            "Post Content:\n",
            "The paper 'Attention Is All You Need' revolutionizes how we approach natural language processing. Introducing the Transformer architecture, it eschews recurrence for self-attention mechanisms, enabling more efficient training and improved performance on various tasks. This innovative model has since become foundational in building state-of-the-art systems across NLP. Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) What's your take on the impact of Transformers in the AI field?\n",
            "\n",
            "#MachineLearning #AI #Transformers #DeepLearning #NLP\n",
            "\n",
            "Style Checklist:\n",
            "□ Appropriate tone for platform\n",
            "□ Within character limits\n",
            "□ Follows platform best practices\n",
            "□ Engaging and accessible language\n",
            "□ Proper use of hashtags and mentions\n",
            "\n",
            "Best Practices for LinkedIn:\n",
            "- Start with a hook\n",
            "- Use line breaks for readability\n",
            "- End with a question or call-to-action\n",
            "\n",
            "Recommendations:\n",
            "- Ensure the tone matches the platform audience\n",
            "- Check character count and hashtag usage\n",
            "- Verify engagement potential\n",
            "\n",
            "📝 transformer_linkedin_post.txt:\n",
            "------------------------------\n",
            "Platform: linkedin\n",
            "Character count: 1199\n",
            "Hashtag count: 5\n",
            "\n",
            "--- POST CONTENT ---\n",
            "🚀 **Transforming Natural Language Processing with Attention Mechanism!** 🌟 \n",
            "\n",
            "In 2017, researchers at Google introduced the \"Attention Is All You Need\" paper, which proposed a revolutionary architecture called the **Transformer**. This model has since become the backbone of many state-of-the-art natural language processing tasks.\n",
            "\n",
            "**Key Insights:**\n",
            "1. 🔑 **Attention Mechanism**: Instead of traditional recurrent networks, the Transformer relies on an attention mechanism that allows parallel processing of data, significantly speeding up training.\n",
            "2. 🏗️ **Two-Stage Structure**: The architecture consists of an encoder and a decoder, each composed of multiple layers, utilizing multi-head attention to capture various representations of the input sequence.\n",
            "3. ⚡ **Impact on AI**: This paper has laid the groundwork for advancements in machine translation, text summarization, and more, leading to the AI boom we see today.\n",
            "\n",
            "Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) \n",
            "\n",
            "#AI #MachineLearning #NLP #Transformers #DeepLearning\n",
            "\n",
            "#AI #MachineLearning #NLP #Transformers #DeepLearning\n",
            "\n",
            "#MachineLearning #AI #Research\n",
            "\n",
            "📝 transformer_paper_linkedin_post.txt:\n",
            "------------------------------\n",
            "Platform: linkedin\n",
            "Character count: 1185\n",
            "Hashtag count: 8\n",
            "\n",
            "--- POST CONTENT ---\n",
            "🌟 Transforming the future of Natural Language Processing! 🌟 \n",
            "\n",
            "The groundbreaking paper \"Attention Is All You Need\" by Vaswani et al. introduced the revolutionary Transformer architecture that has reshaped the landscape of AI. 🚀 Here are some key highlights: \n",
            "\n",
            "🔹 **Transformer Architecture**: A new framework that changed the way we process language data.\n",
            "🔹 **Self-Attention Mechanism**: Say goodbye to RNNs and CNNs! This innovative approach allows models to focus on relevant words in a sentence without traditional sequential processing.\n",
            "🔹 **Parallel Processing**: Improved efficiency means faster training and better performance. 💡\n",
            "🔹 **Foundation for the Giants**: Laid the groundwork for BERT, GPT, and all modern LLMs that we rely on today.\n",
            "🔹 **State-of-the-Art Translation**: Achieved unparalleled results, setting a new benchmark for translation tasks. \n",
            "\n",
            "The impact of this paper is immeasurable, fueling advancements in AI-driven tools and applications. Read it if you haven't already! 📘💻 \n",
            "\n",
            "#MachineLearning #AI #NLP #Transformers #DeepLearning #BERT #GPT #Innovation\n",
            "\n",
            "#MachineLearning #AI #NLP #Transformers #DeepLearning #BERT #GPT #Innovation\n",
            "\n",
            "#MachineLearning #AI #Research\n",
            "\n",
            "📝 linkedin_attention_verification_report.txt:\n",
            "------------------------------\n",
            "TECHNICAL ACCURACY VERIFICATION REPORT\n",
            "\n",
            "Paper Information:\n",
            "\"Attention Is All You Need\" introduced the Transformer model, a novel neural network architecture that discards recurrence and convolution in favor of self-attention mechanisms. This approach significantly enhances efficiency and performance for sequence-to-sequence tasks, such as machine translation and text summarization.\n",
            "\n",
            "Social Media Post:\n",
            "The paper 'Attention Is All You Need' revolutionizes how we approach natural language processing. Introducing the Transformer architecture, it eschews recurrence for self-attention mechanisms, enabling more efficient training and improved performance on various tasks. This innovative model has since become foundational in building state-of-the-art systems across NLP. Check out the full paper for an in-depth understanding of this innovative approach! 🌐 [Read More](https://arxiv.org/abs/1706.03762) What's your take on the impact of Transformers in the AI field? #MachineLearning #AI #Transformers #DeepLearning #NLP\n",
            "\n",
            "Verification Checklist:\n",
            "□ Technical claims are accurate\n",
            "□ No oversimplification that leads to misinformation\n",
            "□ Proper attribution to authors\n",
            "□ Results and claims are not exaggerated\n",
            "□ Methodology is correctly described\n",
            "\n",
            "Recommendations:\n",
            "- Check for any technical inaccuracies\n",
            "- Ensure claims are supported by the paper\n",
            "- Verify that complex concepts are simplified appropriately\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display all files created during the process\n",
        "print(\"📄 Files created during the process:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if WORKING_DIRECTORY.exists():\n",
        "    for file_path in WORKING_DIRECTORY.rglob(\"*\"):\n",
        "        if file_path.is_file():\n",
        "            print(f\"\\n📝 {file_path.name}:\")\n",
        "            print(\"-\" * 30)\n",
        "            with open(file_path, 'r') as f:\n",
        "                content = f.read()\n",
        "                print(content)\n",
        "else:\n",
        "    print(\"❌ No files found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
